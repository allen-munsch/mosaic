Refactoring Plan
lib/mosaic/shard_router.ex

Replace GenServer.call with Registry + pooled workers (3-5 instances)
Add handle_call(:refresh_centroids, ...) that recomputes from shard samples
Add adaptive shard selection: skip shards once cumulative similarity score plateaus

lib/mosaic/query_engine.ex

Convert to pooled workers via Poolboy or :pg process group
Add invalidate_cache(shard_id) public function, call from Indexer
Implement early termination: stop shard search when top-k scores stabilize

lib/mosaic/embedding_service.ex

Shard by text hash across N workers: Registry.lookup(EmbeddingWorkers, :erlang.phash2(text, N))
Or use Poolboy with checkout/checkin pattern

lib/mosaic/routing_maintenance.ex

Add handle_info(:refresh_centroids, ...) on interval (hourly)
Sample 100 docs per shard, recompute centroid, update shard_centroids table
Add handle_info(:rebalance_check, ...) - split shards exceeding 2x target size

lib/mosaic/pagerank_computer.ex

Implement in-degree PageRank: SELECT target_id, COUNT(*) as indegree FROM links GROUP BY target_id
Normalize to 0-100 range, batch update documents.pagerank
Schedule via Process.send_after(self(), :compute, interval)

lib/mosaic/indexer.ex

After register_shard/3, call Mosaic.QueryEngine.invalidate_cache(shard_id)
Add shard size check: if doc_count > threshold, trigger split via RoutingMaintenance

lib/mosaic/connection_pool.ex

Add health check on checkout: SELECT 1 before returning conn
Track last-used timestamp, close stale connections (>5min idle)
Implement retry with backoff on failed checkout

lib/mosaic/storage_manager.ex

Add split_shard(path, split_fn) - partition docs by ID hash, create two new shards
Add merge_shards(path1, path2) for underutilized shards

New: lib/mosaic/worker_pool.ex

Generic pooling wrapper using :poolboy or NimblePool
Configure in Application: {Mosaic.WorkerPool, [name: :router_pool, worker: ShardRouter.Worker, size: 5]}
